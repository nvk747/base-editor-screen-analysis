{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making allele frequency plots\n",
    "\n",
    "This notebook contains code to process the CRISPResso \"allele frequency table\" files from base editor validation experiments. The input is are 2 input files: the first contains metainformation about each sample to make the \"allele frequency\" file, and the second contains metainformation to compute correlations between the log-normalized read counts. The output of this file are 3 files for each sgRNA / primer pair: \n",
    "1. a file containing all alleles and their read counts for each sample\n",
    "2. a filtered version of (1) that only contains alleles with at least 1% abundance in any sample\n",
    "3. a file containing the Pearson correlations between log-normalized read counts of each allele with > 100 reads in at least one sample\n",
    "\n",
    "(1) is the starting file used to show the abundance of specific edits over time (code in BEV_aa_over_time.ipynb). (2) is the starting file used to create allele-level heatmaps (this was done using GraphPad Prism). (3) is the starting file for the plots showing the replicate correlation for validation experiments (actual plots were made using GraphPad Prism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import base_edit_functions_v3 as be\n",
    "from math import log\n",
    "from os import path\n",
    "import sys, itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 2.7.9 |Continuum Analytics, Inc.| (default, Dec 15 2014, 10:37:34) \n",
      "[GCC 4.2.1 (Apple Inc. build 5577)]\n"
     ]
    }
   ],
   "source": [
    "print('Python version: ' + sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 0.23.4\n",
      "numpy 1.16.2\n"
     ]
    }
   ],
   "source": [
    "modules = ['pandas', 'numpy']\n",
    "for module in modules:\n",
    "    try:\n",
    "        print(module + ' ' + sys.modules[module].__version__)\n",
    "    except:\n",
    "        print(module + ' has no __version__ attribute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sg</th>\n",
       "      <th>sgRNA_sequence</th>\n",
       "      <th>BEV_start</th>\n",
       "      <th>BEV_end</th>\n",
       "      <th>primer</th>\n",
       "      <th>offset</th>\n",
       "      <th>rev_com</th>\n",
       "      <th>BEV_ref</th>\n",
       "      <th>BEV_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sg31</td>\n",
       "      <td>GGTGGCCTACAGTCTGCTCA</td>\n",
       "      <td>114</td>\n",
       "      <td>123</td>\n",
       "      <td>PARP1_F3_PARP1_R3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>116;117</td>\n",
       "      <td>118;119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sg31</td>\n",
       "      <td>GGTGGCCTACAGTCTGCTCA</td>\n",
       "      <td>114</td>\n",
       "      <td>123</td>\n",
       "      <td>PARP1_F3_PARP1_R3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>120;121</td>\n",
       "      <td>122;123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sg31</td>\n",
       "      <td>GGTGGCCTACAGTCTGCTCA</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>PARP1_F3_PARP1_R3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7;8</td>\n",
       "      <td>7;8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sg32</td>\n",
       "      <td>CAGGATCCCAGCAAAGTTGG</td>\n",
       "      <td>124</td>\n",
       "      <td>149</td>\n",
       "      <td>PARP1_F2_PARP1_R2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>126;127</td>\n",
       "      <td>128;129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sg32</td>\n",
       "      <td>CAGGATCCCAGCAAAGTTGG</td>\n",
       "      <td>124</td>\n",
       "      <td>149</td>\n",
       "      <td>PARP1_F2_PARP1_R2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>126;127</td>\n",
       "      <td>130;131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sg        sgRNA_sequence  BEV_start  BEV_end             primer  offset  \\\n",
       "0  sg31  GGTGGCCTACAGTCTGCTCA        114      123  PARP1_F3_PARP1_R3       1   \n",
       "1  sg31  GGTGGCCTACAGTCTGCTCA        114      123  PARP1_F3_PARP1_R3       1   \n",
       "2  sg31  GGTGGCCTACAGTCTGCTCA          7        8  PARP1_F3_PARP1_R3       1   \n",
       "3  sg32  CAGGATCCCAGCAAAGTTGG        124      149  PARP1_F2_PARP1_R2       1   \n",
       "4  sg32  CAGGATCCCAGCAAAGTTGG        124      149  PARP1_F2_PARP1_R2       1   \n",
       "\n",
       "   rev_com  BEV_ref BEV_test  \n",
       "0     True  116;117  118;119  \n",
       "1     True  120;121  122;123  \n",
       "2     True      7;8      7;8  \n",
       "3     True  126;127  128;129  \n",
       "4     True  126;127  130;131  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Read in first metainformation file\n",
    "\n",
    "COLUMNS\n",
    "-------\n",
    "\n",
    "sg : sg number (as referenced in paper / supplementary tables)\n",
    "sgRNA_sequence : sequence of sg\n",
    "BEV_start : BEV number for first sample in sg\n",
    "BEV_end : BEV number for last sample in sg\n",
    "primer : name of primer pair used to amplify genomic locus\n",
    "offset : frame for translation (manually determined for each sg / primer pair)\n",
    "rev_com : whether or not to reverse complement the Aligned_Sequence prior to translation (manually determined for each sg / primer pair)\n",
    "BEV_ref : reference sample for log-fold change (LFC) calculation; if multiple BEV numbers are given, these are replicates that will be averaged\n",
    "BEV_test : test sample for LFC calculation; if multiple BEV numbers are given, these are replicates that will be averaged\n",
    "\n",
    "'''\n",
    "\n",
    "input_file = pd.read_csv('../Data/Validation_CRISPResso_results/allele_freq/BEV_allele_freq_input_v3.csv')\n",
    "input_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sg</th>\n",
       "      <th>reps_for_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sg24</td>\n",
       "      <td>348;349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sg24</td>\n",
       "      <td>350;351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sg25</td>\n",
       "      <td>352;353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sg25</td>\n",
       "      <td>354;355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sg26</td>\n",
       "      <td>356;357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sg reps_for_correlation\n",
       "0  sg24              348;349\n",
       "1  sg24              350;351\n",
       "2  sg25              352;353\n",
       "3  sg25              354;355\n",
       "4  sg26              356;357"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Read in correlation metainformation file\n",
    "\n",
    "COLUMNS\n",
    "-------\n",
    "sg : sg number (as referenced in paper / supplementary tables)\n",
    "reps_for_correlation : semicolon-separated BEV numbers of which to calculate the pairwise Pearson correlation of the log-normalized read counts\n",
    "\n",
    "'''\n",
    "\n",
    "corr_input = pd.read_csv('../Data/Validation_CRISPResso_results/allele_freq/BEV_allele_corr_input_v2.csv')\n",
    "corr_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts the BEV number from an int to a 3-digit string\n",
    "def get_bev_str(bev):\n",
    "    bev = int(bev)\n",
    "    if bev < 10:\n",
    "        return '00'+str(bev)\n",
    "    if bev < 100:\n",
    "        return '0'+str(bev)\n",
    "    return str(bev)\n",
    "\n",
    "# This function returns False for any rows (alleles) that have a value < the given value in ALL of the given cols\n",
    "def read_count_filter(row,cols,val):\n",
    "    for col in cols:\n",
    "        if row[col] > val:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# This function returns the tranlation of a given sequence and frame\n",
    "def translate(seq, frame, codon_map):\n",
    "    aa = ''\n",
    "    i = frame - 1\n",
    "    while i < len(seq):\n",
    "        substring = ''\n",
    "        while len(substring) < 3:\n",
    "            if i < len(seq):                \n",
    "                if seq[i] != '-':\n",
    "                    substring += seq[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        if len(substring) == 3:\n",
    "            if 'N' in substring:\n",
    "                aa = aa + '-'\n",
    "            else:\n",
    "                aa = aa + codon_map[substring]\n",
    "    return aa\n",
    "\n",
    "codon_map = {'TTT':'F', 'TTC':'F', 'TTA':'L', 'TTG':'L', 'CTT':'L', 'CTC':'L', 'CTA':'L', 'CTG':'L', 'ATT':'I', 'ATC':'I',\n",
    "             'ATA':'I', 'ATG':'M', 'GTT':'V', 'GTC':'V', 'GTA':'V', 'GTG':'V', 'TCT':'S', 'TCC':'S', 'TCA':'S', 'TCG':'S',\n",
    "             'CCT':'P', 'CCC':'P', 'CCA':'P', 'CCG':'P', 'ACT':'T', 'ACC':'T', 'ACA':'T', 'ACG':'T', 'GCT':'A', 'GCC':'A',\n",
    "             'GCA':'A', 'GCG':'A', 'TAT':'Y', 'TAC':'Y', 'TAA':'*', 'TAG':'*', 'CAT':'H', 'CAC':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "             'AAT':'N', 'AAC':'N', 'AAA':'K', 'AAG':'K', 'GAT':'D', 'GAC':'D', 'GAA':'E', 'GAG':'E', 'TGT':'C', 'TGC':'C',\n",
    "             'TGA':'*', 'TGG':'W', 'CGT':'R', 'CGC':'R', 'CGA':'R', 'CGG':'R', 'AGT':'S', 'AGC':'S', 'AGA':'R', 'AGG':'R',\n",
    "             'GGT':'G', 'GGC':'G', 'GGA':'G', 'GGG':'G'}\n",
    "\n",
    "# This function merges together the \"Allele_frequency_table_around_sgRNA\" files\n",
    "def merge_bev_file(filepath,bev,sg_seq,existing_df,cols):\n",
    "    if not path.exists(filepath):\n",
    "        print 'no file'\n",
    "        return existing_df,cols\n",
    "    df = pd.read_table(filepath,index_col=False)\n",
    "    # Sum together any rows that share both 'Aligned Sequence' and 'Reference Sequence' with each other (this is rare)\n",
    "    df_summed = df[['Aligned_Sequence','Reference_Sequence','#Reads','%Reads']].groupby(['Aligned_Sequence','Reference_Sequence'],as_index=False).agg('sum')\n",
    "    cols.append(str('_BEV_'+str(bev)))\n",
    "    df_summed = df_summed.rename(columns={'#Reads':str('#Reads_BEV_'+str(bev)),'%Reads':str('%Reads_BEV_'+str(bev))})\n",
    "    # Outer merge onto existing dataframe\n",
    "    merge = pd.merge(existing_df,df_summed,how='outer',on=['Aligned_Sequence','Reference_Sequence'])\n",
    "    # Fill in nans with 0\n",
    "    merge = merge.fillna(0)\n",
    "    return merge,cols\n",
    "\n",
    "def check_filepath(filepath,bev,primer,sg_seq):\n",
    "    file_loc = filepath+'/CRISPResso_on_'+bev+'_'+primer+'/'+'Alleles_frequency_table_around_sgRNA_'+sg_seq+'.txt'\n",
    "    if path.exists(file_loc):\n",
    "        return file_loc\n",
    "    return ''\n",
    "        \n",
    "# This function gets the filepath from Base Editing shared drive\n",
    "def get_path(bev_num,primer,sg_seq):\n",
    "    bev = 'BEV_' + get_bev_str(bev_num)\n",
    "    filepath = '../Data/Validation_CRISPResso_results/Completed_CRISPResso_files_v2'\n",
    "    return check_filepath(filepath,bev,primer,sg_seq)\n",
    "\n",
    "# This function gets and merges all \"Allele_frequency_table_around_sgRNA\" files for a given sgRNA sequence\n",
    "# (i.e. different replicates, drug conditions, etc.)\n",
    "# This is customized to work with files with the \"BEV\" notation, stored on the Base Editing shared drive\n",
    "def get_bev_files(bev_list):\n",
    "    merge = pd.DataFrame(columns=['Aligned_Sequence','Reference_Sequence'])\n",
    "    cols = []\n",
    "    for bev,sg_seq,primer_name in bev_list:\n",
    "        filepath = get_path(bev,primer_name,sg_seq)\n",
    "        if filepath != '':\n",
    "            merge,cols = merge_bev_file(filepath=filepath,bev=bev,sg_seq=sg_seq,existing_df=merge,cols=cols)\n",
    "    return merge,cols\n",
    "\n",
    "# This function returns True if the allele is unedited (i.e. WT) and False otherwise\n",
    "def get_wt_col(row):\n",
    "    if row['Aligned_Sequence'] == row['Reference_Sequence']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "'''\n",
    "This function calculates the LFC\n",
    "\n",
    "INPUTS\n",
    "------\n",
    "row : row of metainformation input file containing BEV_test and BEV_ref columns\n",
    "data_file : merged dataframe containing log-normalized rpm for each allele\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "data_file : merged dataframe, now with LFC columns for each BEV test / ref pair\n",
    "\n",
    "'''\n",
    "def get_lfc_v2(row,data_file):\n",
    "    cols = []\n",
    "    bev_list = row['BEV_test'].split(';')\n",
    "    \n",
    "    # Go through each test sample in BEV_test column\n",
    "    for i,bev in enumerate(bev_list):\n",
    "        test = get_bev_str(bev)\n",
    "        \n",
    "        # Get reference sample for LFC from BEV_ref column\n",
    "        ref = get_bev_str(row['BEV_ref'].split(';')[i])\n",
    "        \n",
    "        # Calculate LFC\n",
    "        data_file['LFC_'+test+'-'+ref] = data_file['#Reads_BEV_'+test+';lognorm'] - data_file['#Reads_BEV_'+ref+';lognorm']  \n",
    "        cols.append('LFC_'+test+'-'+ref)\n",
    "        \n",
    "    # Average together LFC columns\n",
    "    data_file['AvgLFC_'+'_'.join(bev_list)] = data_file.loc[:,cols].mean(axis=1)\n",
    "    return data_file\n",
    "\n",
    "def process_data_v2(data):\n",
    "    cols_to_use = []\n",
    "    bev_list = []\n",
    "    for i,row in data.iterrows():\n",
    "        for bev in range(row['BEV_start'],row['BEV_end']+1):\n",
    "            bev_list.append((get_bev_str(bev),row['sgRNA_sequence'],row['primer']))\n",
    "\n",
    "    merge,cols = get_bev_files(bev_list)\n",
    "    \n",
    "    # Calculate log-normalized reads per million for each col\n",
    "    for col in ['#Reads'+col for col in cols]:\n",
    "        colsum = merge[col].sum()\n",
    "        merge.loc[:,str(col+';lognorm')] = merge[col].apply(lambda x: log((float(x)/float(colsum))*1000000 + 1,2))\n",
    "        \n",
    "    # Apply read count filter\n",
    "    merge.loc[:,'%read_count_filter'] = merge.apply(read_count_filter,args=(['%Reads'+col for col in cols],1),axis=1) # less than 1% of all reads\n",
    "    merge.loc[:,'#read_count_filter'] = merge.apply(read_count_filter,args=(['#Reads'+col for col in cols],100),axis=1) # less than 100 reads\n",
    "    \n",
    "    # Reverse complement if necessary\n",
    "    if row['rev_com']:\n",
    "        merge.loc[:,'Aligned_Sequence'] = merge.loc[:,'Aligned_Sequence'].apply(be.revcom)\n",
    "        merge.loc[:,'Reference_Sequence'] = merge.loc[:,'Reference_Sequence'].apply(be.revcom)\n",
    "        \n",
    "    # Translate Aligned_Sequence to amino acids\n",
    "    merge.loc[:,'Translated'] = merge.loc[:,'Aligned_Sequence'].apply(translate,args=(row['offset'],codon_map,))\n",
    "    return merge\n",
    "\n",
    "def get_corr_name(row):\n",
    "    cols = [row['R1'],row['R2']]\n",
    "    cols.sort()\n",
    "    return '_'.join(cols)\n",
    "\n",
    "def get_correlation_cols(corr_input,sg):\n",
    "    corr_input = corr_input.loc[corr_input['sg'] == sg,:]\n",
    "    combos = []\n",
    "    for i,r in corr_input.iterrows():\n",
    "        bevs = r['reps_for_correlation'].split(';')\n",
    "        bevs = ['#Reads_BEV_'+get_bev_str(bev)+';lognorm' for bev in bevs]\n",
    "        if len(bevs) > 1:\n",
    "            combos.extend(itertools.combinations(bevs,2))\n",
    "    combos = ['_'.join(combo) for combo in combos]\n",
    "    return combos\n",
    "\n",
    "def run(input_file,corr_input):\n",
    "\n",
    "    sg_list = list(set(input_file['sg'].tolist())) # drop duplicates from list\n",
    "\n",
    "    # Go through each sgRNA separately    \n",
    "    for sg in sg_list:\n",
    "        print sg\n",
    "        \n",
    "        # Filter input file to contain only rows for given sgRNA\n",
    "        data = input_file.loc[input_file['sg'] == sg,:]\n",
    "        \n",
    "        # Merge all the allele read counts\n",
    "        # To do this, drop the BEV_test and BEV_ref columns (which just have information needed for the LFC calculation)\n",
    "        # Then drop duplicate rows\n",
    "        data_dedup = data.drop_duplicates(subset=['sg','BEV_start','BEV_end','sgRNA_sequence','primer','offset','rev_com'])\n",
    "        merge = process_data_v2(data_dedup)\n",
    "        \n",
    "        # Get the WT column\n",
    "        merge['WT'] = merge.apply(get_wt_col,axis=1)\n",
    "        \n",
    "        # Now, go through each row and calculate the LFC for each of the pairs specified in BEV_test and BEV_ref\n",
    "        for i,r in data.iterrows():               \n",
    "            merge = get_lfc_v2(r,merge)\n",
    "            \n",
    "        # Write out 2 files: full file (merge) and filtered file (only including alleles with > 1% reads in at least one condition)\n",
    "        merge.to_csv('../Data/Validation_CRISPResso_results/allele_freq/'+str(r['sg'])+'_'+r['primer']+'_allele_frequency_table_around_sgRNA.csv',index=False)\n",
    "        filtered = merge[merge['%read_count_filter'] == True]\n",
    "        filtered.to_csv('../Data/Validation_CRISPResso_results/allele_freq/'+str(r['sg'])+'_'+r['primer']+'_filtered_allele_frequency_table_around_sgRNA.csv',\n",
    "                        index=False)            \n",
    "\n",
    "        # Get correlations matrix of log-normalized rpm, using only alleles with > 100 reads in at least one sample\n",
    "        merge = merge[merge['#read_count_filter'] == True]\n",
    "        cols = [x for x in list(merge) if 'lognorm' in x]\n",
    "        correlations = merge[cols].corr(method='pearson')\n",
    "        correlations['R1'] = correlations.index\n",
    "        correlations = correlations.melt(id_vars = 'R1', value_vars=list(correlations).remove('R1'),var_name='R2',value_name='Pearson')\n",
    "        \n",
    "        # Drop correlations that are not specified in corr_input\n",
    "        correlations['Reps'] = correlations.apply(get_corr_name,axis=1)\n",
    "        combos = get_correlation_cols(corr_input,sg)\n",
    "        correlations = correlations[correlations['Reps'].isin(combos)]\n",
    "        \n",
    "        # Drop duplicate rows (i.e. A vs B and B vs A)\n",
    "        correlations = correlations.drop_duplicates(subset=['Reps'])\n",
    "        \n",
    "        # Write to file\n",
    "        correlations.to_csv('../Data/Validation_CRISPResso_results/allele_freq/corr_plots/#read_count_filter_pearson/sg'+str(r['sg'])+'_'+r['primer']+'_correlations.csv')\n",
    "        \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the two input files and produce allele tables for all sgRNAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sg15\n",
      "sg14\n",
      "sg17\n",
      "sg16\n",
      "sg11\n",
      "sg10\n",
      "sg13\n",
      "sg12\n",
      "sg19\n",
      "sg18\n",
      "sg36\n",
      "sg35\n",
      "sg34\n",
      "sg33\n",
      "sg32\n",
      "sg31\n",
      "sg30\n",
      "sg9\n",
      "sg8\n",
      "sg1\n",
      "sg3\n",
      "sg2\n",
      "sg5\n",
      "sg4\n",
      "sg7\n",
      "sg6\n",
      "sg28\n",
      "sg29\n",
      "sg24\n",
      "sg25\n",
      "sg26\n",
      "sg27\n",
      "sg20\n",
      "sg21\n",
      "sg22\n",
      "sg23\n"
     ]
    }
   ],
   "source": [
    "run(input_file,corr_input)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
